{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import rawpy\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.datasets import LabeledDataset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import ignite.distributed as idist\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.metrics import FID, InceptionScore, RunningAverage\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2844, 4248])\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"dataset\"\n",
    "csv_files = [\n",
    "    \"dataset/Sony_train_list.txt\",\n",
    "    # \"dataset/Fuji_train_list.txt\"\n",
    "]\n",
    "\n",
    "batch_size = 6\n",
    "input_size = (2844, 4248)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.CenterCrop(input_size)\n",
    "])\n",
    "dataset = LabeledDataset(root_dir, *csv_files, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=8, shuffle=True)\n",
    "print(dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 11:04:49,651 ignite.distributed.auto.auto_model INFO: Apply torch DataParallel on model\n"
     ]
    }
   ],
   "source": [
    "from unet.unet_model import UNet\n",
    "from torch import optim\n",
    "\n",
    "class Crop(nn.Module):\n",
    "    def __init__(self, scale_factor = 3, *args, **kwargs) -> None:\n",
    "        super(Crop, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        block_shape = (int(x.shape[2]/(self.scale_factor-1)), int(x.shape[3]/(self.scale_factor-1)))\n",
    "        out = torch.zeros((x.shape[0], self.scale_factor**2, *block_shape), dtype=x.dtype, device=idist.device())\n",
    "        block_x_start = 0\n",
    "        for block_x in range(self.scale_factor):\n",
    "            block_y_start = 0\n",
    "            for block_y in range(self.scale_factor):\n",
    "                # print(block_x*self.scale_factor + block_y, '->', block_shape[0]*block_x, ':' ,block_shape[0]*(block_x+1), ',' , block_shape[1]*block_y, ':' ,block_shape[1]*(block_y+1))\n",
    "                out[:,block_x*self.scale_factor + block_y,:,:] = x[:,0,block_x_start:block_x_start + block_shape[0], block_y_start:block_y_start + block_shape[1]]\n",
    "                block_y_start += int(block_shape[1]/2)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "class Reconstruct(nn.Module):\n",
    "    def __init__(self, scale_factor = 3, *args, **kwargs) -> None:\n",
    "        super(Reconstruct, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_shape = (int(x.shape[2]*(self.scale_factor-1)), int(x.shape[3]*(self.scale_factor-1)))\n",
    "        out = torch.zeros((x.shape[0], 1, *out_shape), dtype=x.dtype, device=idist.device())\n",
    "        block_x_start = 0\n",
    "        for block_x in range(self.scale_factor):\n",
    "            block_y_start = 0\n",
    "            for block_y in range(self.scale_factor):\n",
    "                out[:,0, block_x_start:block_x_start+x.shape[2],block_y_start:block_y_start+x.shape[3]] += x[:,block_x*self.scale_factor + block_y,:,:]\n",
    "                block_y_start += int(x.shape[3]/2)\n",
    "            block_x_start += int(x.shape[2]/2)\n",
    "\n",
    "        return out\n",
    "\n",
    "scale_factor = 5\n",
    "\n",
    "net = nn.Sequential(\n",
    "    Crop(scale_factor),\n",
    "    UNet(scale_factor*scale_factor, scale_factor*scale_factor),\n",
    "    Reconstruct(scale_factor)\n",
    ")\n",
    "\n",
    "model = idist.auto_model(net)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "DataParallel                                            [6, 1, 2844, 4248]        --\n",
       "├─Sequential: 1-1                                       [3, 1, 2844, 4248]        31,051,865\n",
       "├─Sequential: 1-4                                       --                        (recursive)\n",
       "│    └─Crop: 2-1                                        [3, 25, 711, 1062]        --\n",
       "├─Sequential: 1-3                                       [3, 1, 2844, 4248]        --\n",
       "├─Sequential: 1-4                                       --                        (recursive)\n",
       "│    └─Crop: 2-2                                        [3, 25, 711, 1062]        --\n",
       "│    └─UNet: 2-3                                        [3, 25, 711, 1062]        31,051,865\n",
       "│    └─UNet: 2-8                                        --                        (recursive)\n",
       "│    │    └─DoubleConv: 3-1                             [3, 64, 711, 1062]        51,520\n",
       "│    │    └─DoubleConv: 3-23                            --                        (recursive)\n",
       "│    └─UNet: 2-5                                        [3, 25, 711, 1062]        --\n",
       "│    └─UNet: 2-8                                        --                        (recursive)\n",
       "│    │    └─DoubleConv: 3-3                             [3, 64, 711, 1062]        --\n",
       "│    │    └─DoubleConv: 3-23                            --                        (recursive)\n",
       "│    │    └─Down: 3-5                                   [3, 128, 355, 531]        221,696\n",
       "│    │    └─Down: 3-25                                  --                        (recursive)\n",
       "│    │    └─Down: 3-7                                   [3, 256, 177, 265]        885,760\n",
       "│    │    └─Down: 3-27                                  --                        (recursive)\n",
       "│    │    └─Down: 3-9                                   [3, 512, 88, 132]         3,540,992\n",
       "│    │    └─Down: 3-29                                  --                        (recursive)\n",
       "│    │    └─Down: 3-11                                  [3, 1024, 44, 66]         14,159,872\n",
       "│    │    └─Down: 3-31                                  --                        (recursive)\n",
       "│    │    └─Up: 3-13                                    [3, 512, 88, 132]         9,177,600\n",
       "│    │    └─Up: 3-33                                    --                        (recursive)\n",
       "│    │    └─Up: 3-15                                    [3, 256, 177, 265]        2,295,040\n",
       "│    │    └─Up: 3-35                                    --                        (recursive)\n",
       "│    │    └─Up: 3-17                                    [3, 128, 355, 531]        574,080\n",
       "│    │    └─Up: 3-37                                    --                        (recursive)\n",
       "│    │    └─Up: 3-19                                    [3, 64, 711, 1062]        143,680\n",
       "│    │    └─Up: 3-39                                    --                        (recursive)\n",
       "│    │    └─OutConv: 3-21                               [3, 25, 711, 1062]        1,625\n",
       "│    │    └─OutConv: 3-41                               --                        (recursive)\n",
       "│    └─Reconstruct: 2-7                                 [3, 1, 2844, 4248]        --\n",
       "│    └─UNet: 2-8                                        --                        (recursive)\n",
       "│    │    └─DoubleConv: 3-23                            --                        (recursive)\n",
       "│    │    └─Down: 3-24                                  [3, 128, 355, 531]        --\n",
       "│    │    └─Down: 3-25                                  --                        (recursive)\n",
       "│    │    └─Down: 3-26                                  [3, 256, 177, 265]        --\n",
       "│    │    └─Down: 3-27                                  --                        (recursive)\n",
       "│    │    └─Down: 3-28                                  [3, 512, 88, 132]         --\n",
       "│    │    └─Down: 3-29                                  --                        (recursive)\n",
       "│    │    └─Down: 3-30                                  [3, 1024, 44, 66]         --\n",
       "│    │    └─Down: 3-31                                  --                        (recursive)\n",
       "│    │    └─Up: 3-32                                    [3, 512, 88, 132]         --\n",
       "│    │    └─Up: 3-33                                    --                        (recursive)\n",
       "│    │    └─Up: 3-34                                    [3, 256, 177, 265]        --\n",
       "│    │    └─Up: 3-35                                    --                        (recursive)\n",
       "│    │    └─Up: 3-36                                    [3, 128, 355, 531]        --\n",
       "│    │    └─Up: 3-37                                    --                        (recursive)\n",
       "│    │    └─Up: 3-38                                    [3, 64, 711, 1062]        --\n",
       "│    │    └─Up: 3-39                                    --                        (recursive)\n",
       "│    │    └─OutConv: 3-40                               [3, 25, 711, 1062]        --\n",
       "│    │    └─OutConv: 3-41                               --                        (recursive)\n",
       "│    └─Reconstruct: 2-9                                 [3, 1, 2844, 4248]        --\n",
       "=========================================================================================================\n",
       "Total params: 199,492,260\n",
       "Trainable params: 199,492,260\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 1.91\n",
       "=========================================================================================================\n",
       "Input size (MB): 289.95\n",
       "Forward/backward pass size (MB): 20259.80\n",
       "Params size (MB): 124.21\n",
       "Estimated Total Size (MB): 20673.96\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.randn(batch_size, 1, *input_size)\n",
    "summary(model, input_data = input_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    short, long, cam_model, _, _ = batch\n",
    "    short = short.to(idist.device())\n",
    "    long = long.to(idist.device())\n",
    "    output = model(short)\n",
    "    g_loss = loss(output, long)\n",
    "    g_loss.backward()\n",
    "    optimizer.step()\n",
    "    return {\"Loss_G\": g_loss.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pikachu/.local/lib/python3.10/site-packages/ignite/contrib/handlers/tqdm_logger.py:127: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "trainer = Engine(training_step)\n",
    "RunningAverage(output_transform=lambda x: x[\"Loss_G\"]).attach(trainer, 'Loss_G')\n",
    "ProgressBar().attach(trainer, metric_names=['Loss_G'])\n",
    "\n",
    "G_losses = []\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def store_losses(engine):\n",
    "    o = engine.state.output\n",
    "    G_losses.append(o[\"Loss_G\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 11:04:54,281 ignite.distributed.launcher.Parallel INFO: Initialized processing group with backend: 'nccl'\n",
      "2023-06-02 11:04:54,282 ignite.distributed.launcher.Parallel INFO: - Run '<function training at 0x7f20952b8dc0>' in 1 processes\n",
      "Epoch [1/10]: [96/311]  31%|███       , Loss_G=5.76e+6 [01:31<03:22]"
     ]
    }
   ],
   "source": [
    "def training(*args):\n",
    "    trainer.run(dataloader, max_epochs=10)\n",
    "\n",
    "with idist.Parallel(backend='nccl') as parallel:\n",
    "    parallel.run(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': 10,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, 'model_seed_{}.pt'.format(torch.random.initial_seed()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
