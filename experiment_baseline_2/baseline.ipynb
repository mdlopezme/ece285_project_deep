{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import rawpy\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.datasets import LabeledDataset\n",
    "from utils.preprocess import adjust_black_level\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import ignite.distributed as idist\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.metrics import FID, InceptionScore, RunningAverage\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "torch.manual_seed(9706507364633013713)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"dataset\"\n",
    "sony_csv_files = [\"dataset/Sony_train_list.txt\"]\n",
    "fuji_csv_files =  [\"dataset/Fuji_train_list.txt\"]\n",
    "\n",
    "batch_size = 8\n",
    "input_size = 512\n",
    "\n",
    "pre_crop_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "sony_dataset = LabeledDataset(root_dir, *sony_csv_files, training=True, transform=pre_crop_transform)\n",
    "sony_dataloader = idist.auto_dataloader(sony_dataset, batch_size=batch_size, num_workers=12, shuffle=True, drop_last=True, prefetch_factor=2)\n",
    "print(sony_dataset[0][0].shape)\n",
    "print(sony_dataset[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sony_dataset.prime_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from unet.unet_model import UNet\n",
    "from torch import optim \n",
    "from ignite.handlers.param_scheduler import LRScheduler\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channel, out_channel, 3, padding=1)\n",
    "        self.lrelu1_1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(out_channel, out_channel, 3, padding=1)\n",
    "        self.lrelu1_2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.lrelu1_1(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.lrelu1_2(x)\n",
    "        return x\n",
    "    \n",
    "class UpConcatBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(UpConcatBlock, self).__init__()\n",
    "        self.deconv = nn.ConvTranspose2d(in_channel, in_channel // 2, kernel_size=2, stride=2)\n",
    "        self.conv_block = ConvBlock(in_channel, out_channel)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.deconv(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = torch.nn.functional.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv_block(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_feat):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.down1 = ConvBlock(in_feat, 32)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.down2 = ConvBlock(32, 64)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.down3 = ConvBlock(64, 128)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.down4 = ConvBlock(128, 256)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.down5 = ConvBlock(256, 512)\n",
    "        self.pool5 = nn.MaxPool2d(2)\n",
    "        self.down6 = ConvBlock(512, 1024)\n",
    "        self.pool6 = nn.MaxPool2d(2)\n",
    "        self.down7 = ConvBlock(1024, 2048)\n",
    "        self.pool7 = nn.MaxPool2d(2)\n",
    "        self.down8 = ConvBlock(2048, 4096)\n",
    "\n",
    "        self.up8 = UpConcatBlock(4096, 2048)\n",
    "        self.up7 = UpConcatBlock(2048, 1024)\n",
    "        self.up6 = UpConcatBlock(1024, 512)\n",
    "        self.up5 = UpConcatBlock(512, 256)\n",
    "        self.up4 = UpConcatBlock(256, 128)\n",
    "        self.up3 = UpConcatBlock(128, 64)\n",
    "        self.up2 = UpConcatBlock(64, 32)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(32, 12, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        down1 = self.down1(x)\n",
    "        down2 = self.down2(self.pool1(down1))\n",
    "        down3 = self.down3(self.pool2(down2))\n",
    "        down4 = self.down4(self.pool3(down3))\n",
    "        down5 = self.down5(self.pool4(down4))\n",
    "        down6 = self.down6(self.pool5(down5))\n",
    "        down7 = self.down7(self.pool6(down6))\n",
    "        down8 = self.down8(self.pool7(down7))\n",
    "\n",
    "        up = self.up8(down8, down7)\n",
    "        up = self.up7(up, down6)\n",
    "        up = self.up6(up, down5)\n",
    "        up = self.up5(up, down4)\n",
    "        up = self.up4(up, down3)\n",
    "        up = self.up3(up, down2)\n",
    "        up = self.up2(up, down1)\n",
    "\n",
    "        out = self.conv10(up)\n",
    "        out = torch.nn.functional.pixel_shuffle(out, 2)\n",
    "        return out\n",
    "\n",
    "net = UNet(4)\n",
    "model = idist.auto_model(net)\n",
    "optimizer = idist.auto_optim(optim.Adam(model.parameters(), lr=1e-4))\n",
    "loss = nn.L1Loss()\n",
    "lr_scheduler = LRScheduler(optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.randn(batch_size, 4, input_size, input_size)\n",
    "summary(model, input_data = input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image_short, image_long, size):\n",
    "    H = image_short.shape[2]\n",
    "    W = image_short.shape[3]\n",
    "    ps = size\n",
    "    xx = np.random.randint(0, W - ps)\n",
    "    yy = np.random.randint(0, H - ps)\n",
    "    image_short = image_short[:,:,yy:yy + ps, xx:xx + ps]\n",
    "    image_long = image_long[:,:,yy * 2:yy * 2 + ps * 2, xx * 2:xx * 2 + ps * 2]\n",
    "    return image_short, image_long\n",
    "\n",
    "def pack_sony_raw(batch, device=None):\n",
    "    if not device:\n",
    "        device = idist.device()\n",
    "    batch = torch.maximum(batch - 512, torch.Tensor([0]).to(device=device)) / (16383 - 512)\n",
    "    H = batch.shape[2]\n",
    "    W = batch.shape[3]\n",
    "\n",
    "    out = torch.cat((batch[:,:, 0:H:2, 0:W:2], \n",
    "                     batch[:,:, 0:H:2, 1:W:2],\n",
    "                     batch[:,:, 1:H:2, 1:W:2],\n",
    "                     batch[:,:, 1:H:2, 0:W:2]), dim=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    short, long, ratio, cam_model, exposure_ratio, _, _ = batch\n",
    "\n",
    "    short = short.to(idist.device())\n",
    "    long = long.to(idist.device())\n",
    "\n",
    "    # short = pack_sony_raw(short)\n",
    "\n",
    "    long = long / 65535.0\n",
    "    short = adjust_black_level(short, device=idist.device())\n",
    "    short = short * exposure_ratio.float().to(idist.device()).view(-1, 1, 1, 1)\n",
    "    # short, long = random_crop(short, long, input_size)\n",
    "\n",
    "    output = model(short)\n",
    "\n",
    "    g_loss = loss(output, long)\n",
    "        \n",
    "    g_loss.backward()\n",
    "    optimizer.step()\n",
    "    return {\"Loss_G\": g_loss.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Engine(training_step)\n",
    "trainer.add_event_handler(Events.EPOCH_STARTED, lr_scheduler)\n",
    "RunningAverage(output_transform=lambda x: x[\"Loss_G\"]).attach(trainer, 'Loss_G')\n",
    "ProgressBar().attach(trainer, metric_names=['Loss_G'])\n",
    "\n",
    "G_losses = []\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def store_losses(engine):\n",
    "    o = engine.state.output\n",
    "    print(o[\"Loss_G\"])\n",
    "    G_losses.append(o[\"Loss_G\"])\n",
    "\n",
    "best_l1 = 9999\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def save_checkpoint(engine):\n",
    "    global best_l1\n",
    "    if engine.state.output[\"Loss_G\"] < best_l1:\n",
    "        best_l1 = engine.state.output[\"Loss_G\"]\n",
    "        print('New Best Score')\n",
    "        torch.save({\n",
    "            'epoch': engine.state.epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, 'model_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 100\n",
    "def training(*args):\n",
    "    # with profile(activities=[ProfilerActivity.CPU], record_shapes=True, profile_memory=True, with_stack=True) as prof:\n",
    "    trainer.run(sony_dataloader, max_epochs=num_epoch)\n",
    "\n",
    "    # print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=100))\n",
    "    # print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=100))\n",
    "    # prof.export_chrome_trace(\"trace.json\")\n",
    "    # https://github.com/pytorch/pytorch/issues/100253\n",
    "    # prof.export_stacks(\"profiler_stacks.txt\", \"self_cpu_time_total\")\n",
    "\n",
    "with idist.Parallel(backend='nccl') as parallel:\n",
    "    parallel.run(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"L1 Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': num_epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, 'model_seed_{}.pt'.format(torch.random.initial_seed()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('model_seed_{}.pt'.format(9706507364633013713))\n",
    "# checkpoint = torch.load('model_seed_{}.pt'.format(torch.random.initial_seed()))\n",
    "best_model = idist.auto_model(\n",
    "    UNet(4)\n",
    ")\n",
    "\n",
    "best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "root_dir = \"dataset\"\n",
    "sony_test_csv_files = [\"dataset/Sony_test_list.txt\"]\n",
    "\n",
    "sony_test_dataset = LabeledDataset(root_dir, *sony_test_csv_files, transform=transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "]))\n",
    "sony_test_dataloader = DataLoader(sony_test_dataset, batch_size=1, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    best_model.eval()\n",
    "    list_samp = [1, 13, 27, 39, 51, 61, 73]\n",
    "    o = 0\n",
    "    for batch in sony_test_dataloader:\n",
    "    # batch = next(iter(sony_test_dataloader))\n",
    "        short, long, ratio, cam_model, exposure_ratio, _, _, short_raw = batch\n",
    "        o += 1\n",
    "        if o > list_samp[-1]:\n",
    "            break\n",
    "        if o not in list_samp:\n",
    "            continue\n",
    "        short_ = short\n",
    "        short = short.to(idist.device())\n",
    "        long = long.to(idist.device())\n",
    "\n",
    "        short = pack_sony_raw(short)\n",
    "        print(torch.mean(short), torch.median(short), torch.min(short), torch.max(short))\n",
    "        long = long / 65535.0\n",
    "        short = short * exposure_ratio.float().to(idist.device()).view(-1, 1, 1, 1)\n",
    "        print(torch.mean(short), torch.median(short), torch.min(short), torch.max(short))\n",
    "        \n",
    "        \n",
    "        output = best_model(short)\n",
    "        # output = torch.nn.functional.pixel_shuffle(output, 2)\n",
    "\n",
    "        output = output[0, :, :, :].to('cpu').numpy()\n",
    "        output = np.minimum(np.maximum(output, 0), 1)\n",
    "        gt_full = long[0, :, :, :].to('cpu').numpy()\n",
    "        raw_input = short_raw[0, :, :, :].to('cpu').numpy() / 65535.0\n",
    "        scale_full = np.float32(short_raw[0, :, :, :].to('cpu').numpy() / 65535.0)\n",
    "        scale_full = scale_full * np.mean(gt_full) / np.mean(scale_full) \n",
    "\n",
    "        print(np.mean(output[0]), np.median(output[0]), np.min(output[0]), np.max(output[0]))\n",
    "        print(np.mean(output[1]), np.median(output[1]), np.min(output[1]), np.max(output[1]))\n",
    "        print(np.mean(output[2]), np.median(output[2]), np.min(output[2]), np.max(output[2]))\n",
    "        print(np.mean(gt_full[0]), np.median(gt_full[0]), np.min(gt_full[0]), np.max(gt_full[0]))\n",
    "        print(np.mean(gt_full[1]), np.median(gt_full[1]), np.min(gt_full[1]), np.max(gt_full[1]))\n",
    "        print(np.mean(gt_full[2]), np.median(gt_full[2]), np.min(gt_full[2]), np.max(gt_full[2]))\n",
    "\n",
    "        output = np.minimum(np.transpose(output, (1,2,0)) * 255, 255).astype(np.uint8)\n",
    "        # output = (output-np.min(output))/(np.max(output)-np.min(output))\n",
    "        gt_full = np.minimum(np.transpose(gt_full, (1,2,0)) * 255, 255).astype(np.uint8)\n",
    "        raw_input = np.minimum(raw_input * 255, 255).astype(np.uint8)\n",
    "        scale_full = np.minimum(scale_full * 255, 255).astype(np.uint8)\n",
    "\n",
    "        color = ('b','g','r')\n",
    "        plt.figure(figsize=(15,15))\n",
    "        ax = plt.subplot(4,4,1)\n",
    "        ax.set_title(\"Input\")\n",
    "        ax.set_ylim([0, 1e6])\n",
    "        for i,col in enumerate(color):\n",
    "            histr = cv2.calcHist([raw_input],[i],None,[256],[0,256])\n",
    "            plt.plot(histr,color = col)\n",
    "            plt.xlim([0,256])\n",
    "        plt.subplot(4,4,5)\n",
    "        plt.imshow(raw_input)\n",
    "\n",
    "        ax = plt.subplot(4,4,2)\n",
    "        ax.set_title(\"Histogram Stretching\")\n",
    "        ax.set_ylim([0, 1e6])\n",
    "        for i,col in enumerate(color):\n",
    "            histr = cv2.calcHist([scale_full],[i],None,[256],[0,256])\n",
    "            plt.plot(histr,color = col)\n",
    "            plt.xlim([0,256])\n",
    "        plt.subplot(4,4,6)\n",
    "        plt.imshow(scale_full)\n",
    "\n",
    "        ax = plt.subplot(4,4,3)\n",
    "        ax.set_title(\"Network Output\")\n",
    "        ax.set_ylim([0, 1e6])\n",
    "        for i,col in enumerate(color):\n",
    "            histr = cv2.calcHist([output],[i],None,[256],[0,256])\n",
    "            plt.plot(histr,color = col)\n",
    "            plt.xlim([0,256])\n",
    "        plt.subplot(4,4,7)\n",
    "        plt.imshow(output)\n",
    "\n",
    "        ax = plt.subplot(4,4,4)\n",
    "        ax.set_title(\"Ground Truth\")\n",
    "        ax.set_ylim([0, 1e6])\n",
    "        for i,col in enumerate(color):\n",
    "            histr = cv2.calcHist([gt_full],[i],None,[256],[0,256])\n",
    "            plt.plot(histr,color = col)\n",
    "            plt.xlim([0,256])\n",
    "        plt.subplot(4,4,8)\n",
    "        plt.imshow(gt_full)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.metrics import PSNR, SSIM\n",
    "\n",
    "def eval_step(engine, batch):\n",
    "    short, long, ratio, cam_model, exposure_ratio, _, _, short_raw = batch\n",
    "\n",
    "    short = short.to(idist.device())\n",
    "    long = long.to(idist.device())\n",
    "\n",
    "    short = pack_sony_raw(short)\n",
    "    long = long / 65535.0\n",
    "    short = short * exposure_ratio.float().to(idist.device()).view(-1, 1, 1, 1)   \n",
    "    \n",
    "    output = best_model(short)\n",
    "    output = torch.minimum(torch.maximum(output, torch.Tensor([0]).to(idist.device())), torch.Tensor([1]).to(idist.device()))\n",
    "\n",
    "    return output, long\n",
    "\n",
    "evaluator = Engine(eval_step)\n",
    "psnr = PSNR(data_range=1.0)\n",
    "psnr.attach(evaluator, 'psnr')\n",
    "ssim = SSIM(data_range=1.0)\n",
    "ssim.attach(evaluator, 'ssim')\n",
    "ProgressBar().attach(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"dataset\"\n",
    "sony_val_csv_files = [\"dataset/Sony_test_list.txt\"]\n",
    "\n",
    "sony_val_dataset = LabeledDataset(root_dir, *sony_val_csv_files, training=False, transform=transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "]))\n",
    "sony_val_dataloader = idist.auto_dataloader(sony_val_dataset, batch_size=2, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = evaluator.run(sony_val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state.metrics['psnr'])\n",
    "print(state.metrics['ssim'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
